{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation: From $[0,1]$ space to $\\mathbb{R}$ space \n",
    "\n",
    "As we are trying to assess the representativeness of the number of guests before and after the *break-point*, thereby assess whether there is a **structural-change** in our hotel bookings system, we need to model using proportions, `proportion_guests`. This is because we expect the number of guests to change after the potential **structural-change**, but if we can assess whether the proportions are the same or even similar, then we can still make inferences from our data before and after the change. \n",
    "\n",
    "This is because the similar proportions will suggest that whilst the absolute number of guests making hotel bookings have changed, the proportion of people from each group, `region`, are similar, so our data after the *break-point* is still representative of the old data before the *break-point*, and henceforth, any inferences still hold for the same population.\n",
    "\n",
    "You can think of this in the sense that before the *break-point*, we had our target **population** being captured in our data. If the proportions/compositions of people from each `region` are similar after the *break-point*, then we have a **representative sample** of our **target population**.\n",
    "\n",
    "However, we cannot model on proportion/compositional data because compositional data is bounded in the region $[0,1]$. There is a risk here that applying a model to it can give values outside this region, and henceforth be entirely meaningless because you cannot interpret such a value.\n",
    "\n",
    "Instead, we can transform our compositional data by mapping our data into the real number space, $\\mathbb{R}%$. There are three well-characterised isomorphisms that do this:\n",
    "\n",
    "- **Additive logratio (alr)**\n",
    "- **Centre logratio (clr)**\n",
    "- **Isometric logratio (ilr)**\n",
    "\n",
    "*Source: [Wikipedia](https://en.wikipedia.org/wiki/Compositional_data)*\n",
    "\n",
    "Alternatively, we can apply the following by adding a very small value to $0$ values for our proportions. In particular, it is also a common transformation to transform data to be approximately **normally-distributed**. \n",
    "\n",
    "*Source: [Feng et al., \"Log-transformation and its implications for data analysis\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4120293/)*\n",
    "\n",
    "- **Log transform** \n",
    "\n",
    "In all these transformations, it is essential that our data does not contain any zeroes in. Thus we will use a multiplicative replacement strategy to replace zeroes with a small, positive $\\delta$, and do so in a way that ensures the compositions still add up to $1$.\n",
    "\n",
    "*Source: [J.A. Martin Fernandez, \"Dealing with Zeros and Missing Values in Compositional Data Sets Using Nonparametric Imputation\"](https://link.springer.com/article/10.1023/A:1023866030544)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skbio.stats.composition import multiplicative_replacement\n",
    "from skbio.stats.composition import clr\n",
    "from skbio.stats.composition import ilr\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# display multiple outputs in same cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# put in a python script\n",
    "# create custom additive log-ratio function\n",
    "def func_alr(mat, div):\n",
    "    \n",
    "    # check to see division can happen /log(0)\n",
    "    \n",
    "    # take vectors from input array `mat`, excluding column index, `div`\n",
    "    numerator = np.delete(arr = mat, obj = div, axis = 1)\n",
    "    # take vector for `div`\n",
    "    denominator = mat[:, div]\n",
    "    \n",
    "    # take logs - should find way to call a package within a function\n",
    "    lnum = np.log(numerator)\n",
    "    lden = np.log(denominator)\n",
    "    \n",
    "    # subtract 'div' vector from every 'column' in matrix, 'mat'\n",
    "    # https://stackoverflow.com/questions/26333005/numpy-subtract-every-row-of-matrix-by-vector\n",
    "    output = (lnum.transpose() - lden).transpose()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>region</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>Africa</th>\n",
       "      <th>Americas</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Oceania</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989071</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.938525</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027586</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "region arrival_date    Africa  Americas      Asia    Europe  Oceania\n",
       "0        2015-07-01  0.000000  0.010929  0.000000  0.989071      0.0\n",
       "1        2015-07-02  0.000000  0.054795  0.027397  0.917808      0.0\n",
       "2        2015-07-03  0.000000  0.103896  0.000000  0.896104      0.0\n",
       "3        2015-07-04  0.000000  0.000000  0.000000  1.000000      0.0\n",
       "4        2015-07-05  0.000000  0.077922  0.000000  0.922078      0.0\n",
       "..              ...       ...       ...       ...       ...      ...\n",
       "788      2017-08-27  0.000000  0.094862  0.023715  0.881423      0.0\n",
       "789      2017-08-28  0.000000  0.049180  0.012295  0.938525      0.0\n",
       "790      2017-08-29  0.000000  0.027586  0.096552  0.875862      0.0\n",
       "791      2017-08-30  0.016667  0.100000  0.050000  0.833333      0.0\n",
       "792      2017-08-31  0.011050  0.022099  0.033149  0.933702      0.0\n",
       "\n",
       "[793 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in variable from other notebook\n",
    "%store -r data_join\n",
    "\n",
    "# pivot so can apply trasnformations on\n",
    "data_pivot = data_join.pivot(index = 'arrival_date', columns = 'region', values = 'proportion_guests')\n",
    "\n",
    "# replace NaNs with 0s so can transform\n",
    "data_pivot = data_pivot.loc[:, 'Africa':'Oceania'].fillna(value = 0, axis = 1)\n",
    "\n",
    "## un-groupby so we get previous grouped index as columns\n",
    "data_pivot = data_pivot.reset_index()\n",
    "data_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Let's start by dealing with $0$s in our data by applying the *multiplicative replacement* strategy to replace 0s with a small enough number that will not change the overall modelling but ensures our proportions/compositions still sum to $1$ at the same time.\n",
    "\n",
    "We are also extracting the specific part of the dataframe that we will apply our transformation on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04      , 0.00961749, 0.04      , 0.87038251, 0.04      ],\n",
       "       [0.04      , 0.05041096, 0.02520548, 0.84438356, 0.04      ],\n",
       "       [0.04      , 0.09142857, 0.04      , 0.78857143, 0.04      ],\n",
       "       ...,\n",
       "       [0.04      , 0.02537931, 0.08882759, 0.8057931 , 0.04      ],\n",
       "       [0.016     , 0.096     , 0.048     , 0.8       , 0.04      ],\n",
       "       [0.01060773, 0.02121547, 0.0318232 , 0.89635359, 0.04      ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 extract only part we want to apply transformation on\n",
    "x = data_pivot.loc[:, 'Africa':'Oceania']\n",
    "\n",
    "# 2. store column names for later when re-creating dataframe\n",
    "col_names = list(x)\n",
    "col_names_alr = list(x)\n",
    "\n",
    "# 3. apply multiplicative replacement strategy to replace 0s\n",
    "x = multiplicative_replacement(x)\n",
    "\n",
    "# 3.1 note, returns an array\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of 'Oceania' column\n",
    "index_denominator = col_names_alr.index('Oceania')\n",
    " # remove this index from list of column names\n",
    "del col_names_alr[index_denominator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform the *ALR*, *CLR* and *ILR* tranformations.\n",
    "\n",
    "Note that the column names for ALR and ILR are misleading, they should really be:\n",
    "\n",
    "- **ALR**: Africa/Oceania, Americas/Oceania, ...\n",
    "- **ILR**: Africa\\~Americas, Americas\\~Asia, ...\n",
    "\n",
    "*Source: [StackExchange answer by marc1s](https://stats.stackexchange.com/a/244446/276516)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_join' (DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>region</th>\n",
       "      <th>total_guests</th>\n",
       "      <th>proportion_guests</th>\n",
       "      <th>alr</th>\n",
       "      <th>clr</th>\n",
       "      <th>ilr</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>Americas</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>-1.425297</td>\n",
       "      <td>-1.756248</td>\n",
       "      <td>-0.581875</td>\n",
       "      <td>-4.644172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>Europe</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.989071</td>\n",
       "      <td>3.080053</td>\n",
       "      <td>2.749102</td>\n",
       "      <td>0.370015</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>Americas</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.231329</td>\n",
       "      <td>-0.332519</td>\n",
       "      <td>0.471513</td>\n",
       "      <td>-2.987547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.461818</td>\n",
       "      <td>-1.025666</td>\n",
       "      <td>-2.707678</td>\n",
       "      <td>-3.680694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>Europe</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>3.049727</td>\n",
       "      <td>2.485880</td>\n",
       "      <td>0.630401</td>\n",
       "      <td>-0.169148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>Europe</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>2.368286</td>\n",
       "      <td>0.701506</td>\n",
       "      <td>-0.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>-1.327296</td>\n",
       "      <td>-1.511161</td>\n",
       "      <td>-0.490129</td>\n",
       "      <td>-4.546172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>Americas</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>-0.634149</td>\n",
       "      <td>-0.818014</td>\n",
       "      <td>-0.614037</td>\n",
       "      <td>-3.853025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>Asia</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>-0.228684</td>\n",
       "      <td>-0.412549</td>\n",
       "      <td>-3.325103</td>\n",
       "      <td>-3.447560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>Europe</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>3.109456</td>\n",
       "      <td>2.925590</td>\n",
       "      <td>0.205568</td>\n",
       "      <td>-0.109420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arrival_date    region  total_guests  proportion_guests       alr  \\\n",
       "0      2015-07-01  Americas           2.0           0.010929 -1.425297   \n",
       "1      2015-07-01    Europe         181.0           0.989071  3.080053   \n",
       "2      2015-07-02  Americas           4.0           0.054795  0.231329   \n",
       "3      2015-07-02      Asia           2.0           0.027397 -0.461818   \n",
       "4      2015-07-02    Europe          67.0           0.917808  3.049727   \n",
       "...           ...       ...           ...                ...       ...   \n",
       "2710   2017-08-30    Europe         100.0           0.833333  2.995732   \n",
       "2711   2017-08-31    Africa           2.0           0.011050 -1.327296   \n",
       "2712   2017-08-31  Americas           4.0           0.022099 -0.634149   \n",
       "2713   2017-08-31      Asia           6.0           0.033149 -0.228684   \n",
       "2714   2017-08-31    Europe         169.0           0.933702  3.109456   \n",
       "\n",
       "           clr       ilr       log  \n",
       "0    -1.756248 -0.581875 -4.644172  \n",
       "1     2.749102  0.370015 -0.138822  \n",
       "2    -0.332519  0.471513 -2.987547  \n",
       "3    -1.025666 -2.707678 -3.680694  \n",
       "4     2.485880  0.630401 -0.169148  \n",
       "...        ...       ...       ...  \n",
       "2710  2.368286  0.701506 -0.223144  \n",
       "2711 -1.511161 -0.490129 -4.546172  \n",
       "2712 -0.818014 -0.614037 -3.853025  \n",
       "2713 -0.412549 -3.325103 -3.447560  \n",
       "2714  2.925590  0.205568 -0.109420  \n",
       "\n",
       "[2715 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAN DO ALL THIS IN A FUNCTION AND THEN LOOP ON FUNCTION\n",
    "\n",
    "# 1. apply transformations\n",
    "data_alr = func_alr(mat = x, div = index_denominator)\n",
    "data_clr = clr(mat = x)\n",
    "data_ilr = ilr(mat = x)\n",
    "data_log = np.log(x)\n",
    "\n",
    " # store in list for efficiency\n",
    "data_frames = [data_alr, data_clr, data_ilr, data_log]\n",
    "\n",
    "# 2. convert to dataframe\n",
    "data_frames[0] = pd.DataFrame(data = data_alr, columns = col_names_alr)\n",
    "data_frames[1] = pd.DataFrame(data = data_clr, columns = col_names)\n",
    "data_frames[2] = pd.DataFrame(data = data_ilr, columns = col_names_alr)\n",
    "data_frames[3] = pd.DataFrame(data = data_log, columns = col_names)\n",
    "\n",
    "# 3. rename columns for creating dataframe\n",
    "data_frames[0].columns += '_alr'\n",
    "data_frames[1].columns += '_clr'\n",
    "data_frames[2].columns += '_ilr'\n",
    "data_frames[3].columns += '_log'\n",
    "\n",
    "# 4. add `arrival_date` back in (ASSUMES ROW ORDERING IS PRESERVED)\n",
    "data_frames[0]['arrival_date'] = data_pivot['arrival_date']\n",
    "data_frames[1]['arrival_date'] = data_pivot['arrival_date']\n",
    "data_frames[2]['arrival_date'] = data_pivot['arrival_date']\n",
    "data_frames[3]['arrival_date'] = data_pivot['arrival_date']\n",
    "\n",
    "# 5. merge these dataframes together\n",
    "data_transform = reduce(lambda left, right: pd.merge(left, right, on = ['arrival_date'], how = 'outer'), data_frames)\n",
    "\n",
    "\n",
    "# unpivot\n",
    "data_transform = data_transform.melt(id_vars = ['arrival_date'], var_name = 'region', value_name = 'transform_guests')\n",
    "\n",
    "# split the `region` column into two\n",
    "col_split = data_transform['region'].str.split(pat = '_', expand = True) \n",
    "data_transform['region'] = col_split[0]\n",
    "data_transform['transform_type'] = col_split[1]\n",
    "\n",
    "# pivot on `transform_type`\n",
    "data_transform = data_transform.pivot_table(index = ['arrival_date', 'region'], \n",
    "                                            columns = 'transform_type', \n",
    "                                            values = 'transform_guests')\n",
    "data_transform = data_transform.reset_index()\n",
    "\n",
    "# merge with data_join\n",
    "data_join = pd.merge(left = data_join, right = data_transform,\n",
    "                    how = 'left', left_on = ('arrival_date', 'region'), right_on = ('arrival_date', 'region'),\n",
    "                    validate = 'one_to_one')\n",
    "\n",
    "# store and pass variables between notebooks\n",
    "%store data_join\n",
    "\n",
    "data_join"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
